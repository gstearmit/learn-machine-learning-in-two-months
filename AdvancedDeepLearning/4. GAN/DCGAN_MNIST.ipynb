{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCGAN_MNIST.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"ZPArGdqYMiEO","colab_type":"code","outputId":"f8810eaa-f89a-4c65-8397-0bcad02e1725","executionInfo":{"status":"ok","timestamp":1556038164057,"user_tz":-60,"elapsed":22631,"user":{"displayName":"Tuan Nguyen","photoUrl":"","userId":"16236227979998259496"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"1FFESWHPf4N0","colab_type":"code","outputId":"ece45f0a-d98c-48e8-a871-5cbc21475e83","executionInfo":{"status":"ok","timestamp":1556038168228,"user_tz":-60,"elapsed":2370,"user":{"displayName":"Tuan Nguyen","photoUrl":"","userId":"16236227979998259496"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"cell_type":"code","source":["%cd /content/gdrive/My Drive/Colab Notebooks\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks\n","clr_callback.py\t\t\t  DCGAN_MNIST.ipynb  mnist.ipynb\n","CyclicalLearningRate_MNIST.ipynb  gan\t\t     __pycache__\n"],"name":"stdout"}]},{"metadata":{"id":"AgkZ-dWMbp9X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"368f855b-ab13-4512-eb2d-9b36278264c8","executionInfo":{"status":"ok","timestamp":1556038173212,"user_tz":-60,"elapsed":1837,"user":{"displayName":"Tuan Nguyen","photoUrl":"","userId":"16236227979998259496"}}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","from keras.utils import to_categorical, plot_model\n","from keras.layers import Activation,Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Conv2DTranspose, Reshape, BatchNormalization, LeakyReLU\n","from keras.models import Sequential, Model\n","from keras.optimizers import RMSprop\n","from keras import backend as K\n","import os\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","import os\n","import argparse"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"G3GGWTe-YM_l","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_images(generator,\n","                noise_input,\n","                show=False,\n","                step=0,\n","                model_name=\"gan\"):\n","    \"\"\"Generate fake images and plot them\n","    For visualization purposes, generate fake images\n","    then plot them in a square grid\n","    # Arguments\n","        generator (Model): The Generator Model for fake images generation\n","        noise_input (ndarray): Array of z-vectors\n","        show (bool): Whether to show plot or not\n","        step (int): Appended to filename of the save images\n","        model_name (string): Model name\n","    \"\"\"\n","    os.makedirs(model_name, exist_ok=True)\n","    filename = os.path.join(model_name, \"%05d.png\" % step)\n","    images = generator.predict(noise_input)\n","    plt.figure(figsize=(28, 28))\n","    num_images = images.shape[0]\n","    image_size = images.shape[1]\n","    rows = int(math.sqrt(noise_input.shape[0]))\n","    for i in range(num_images):\n","        plt.subplot(rows, rows, i + 1)\n","        image = np.reshape(images[i], [image_size, image_size])\n","        plt.imshow(image, cmap='gray')\n","        plt.axis('off')\n","    plt.savefig(filename)\n","    if show:\n","        plt.show()\n","    else:\n","        plt.close('all')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w9azSCIHMiET","colab_type":"code","colab":{}},"cell_type":"code","source":["def build_generator(inputs, image_size):\n","    kernel_size = 5\n","    kernel_filters = [128, 64, 32, 1]\n","    image_resize = image_size//4\n","    \n","    x = Dense(image_resize * image_resize * kernel_filters[0])(inputs)\n","    x = Reshape((image_resize, image_resize, kernel_filters[0]))(x)\n","    \n","    for filters in kernel_filters:\n","        if filters > kernel_filters[-2]:\n","            strides = 2\n","        else:\n","            strides = 1\n","        x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = Conv2DTranspose(filters, kernel_size, strides=strides, padding='same')(x)\n","    x = Activation('sigmoid')(x)\n","    generator = Model(inputs=inputs, outputs=x)\n","    return generator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k9Mq89Q9MiEV","colab_type":"code","colab":{}},"cell_type":"code","source":["def build_discriminator(inputs):\n","    x = inputs\n","    kernel_size = 5\n","    kernel_filters = [32, 64, 128, 256]\n","    for filters in kernel_filters:\n","        if filters == kernel_filters[-1]:\n","            strides = 1\n","        else:\n","            strides = 2\n","        x = LeakyReLU(alpha = 0.2)(x)\n","        x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n","    x = Flatten()(x)\n","    x = Dense(1)(x)\n","    x = Activation('sigmoid')(x)\n","    \n","    discriminator = Model(inputs=inputs, outputs=x)\n","    return discriminator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sjdBPWOjMiEY","colab_type":"code","colab":{}},"cell_type":"code","source":["def build_and_train_model(): \n","    (x_train, _), (x_test, _) = mnist.load_data()\n","    image_size = x_train.shape[1]\n","    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n","    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n","\n","    x_train = x_train/255.\n","    x_test = x_test/255.\n","    \n","    latent_size = 100\n","    batch_size = 100\n","    train_steps = 40000\n","    lr = 2e-4\n","    decay = 6e-8\n","    \n","    \n","    # build discriminator\n","    input_shape = (image_size, image_size, 1)\n","    inputs = Input(shape=input_shape)\n","    discriminator = build_discriminator(inputs)\n","    optimizer = RMSprop(lr = lr, decay = decay)\n","    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    #discriminator.summary()\n","    \n","    # build generator\n","    input_shape = (latent_size, )\n","    inputs = Input(shape=input_shape)\n","    generator = build_generator(inputs, image_size)\n","    #generator.summary()\n","    \n","    # build adverserial model\n","    optimizer = RMSprop(lr = lr*0.5, decay = decay*0.5)\n","    discriminator.trainable = False\n","    adversarial = Model(inputs=inputs, outputs=discriminator(generator(inputs)))\n","    adversarial.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    #adversarial.summary()\n","    \n","    # train discriminator and adversarial networks\n","    models = (generator, discriminator, adversarial)\n","    params = (batch_size, latent_size, train_steps)\n","    train(models, x_train, params)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QVjUp29tMiEa","colab_type":"code","colab":{}},"cell_type":"code","source":["def train(models, x_train, params):\n","    generator, discriminator, adversarial = models\n","    batch_size, latent_size, train_steps = params\n","    save_interval = 500\n","    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n","    train_size = x_train.shape[0]\n","    \n","    for i in range(train_steps):\n","        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n","        real_images = x_train[rand_indexes]\n","        noises = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n","        fake_images = generator.predict(noises)\n","        x = np.concatenate((real_images, fake_images))\n","        y = np.ones([2*batch_size, 1])\n","        y[batch_size:,:] = 0.0\n","        \n","        loss, acc = discriminator.train_on_batch(x,y)\n","        log = \"Epochs %d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n","        \n","        noises = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n","        y = np.ones([batch_size, 1])\n","        \n","        loss, acc = adversarial.train_on_batch(noises,y)\n","        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n","        print(log)\n","        \n","        if (i + 1) % save_interval == 0:\n","            if (i + 1) == train_steps:\n","                show = True\n","            else:\n","                show = False\n","            #rand_indexes_draw = np.random.randint(0, 64, size=16)\n","            # plot generator images on a periodic basis\n","            plot_images(generator, noise_input=noise_input,  show=show, step=(i + 1))\n","    generator.save(\"generator.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"udoOlmq8MiEc","colab_type":"code","colab":{}},"cell_type":"code","source":["build_and_train_model()"],"execution_count":0,"outputs":[]}]}