

| 1 | Math Review | Matrix | \- Vector, matrix, tensor \- Matrix multiplication |
| :---- | :---- | :---- | :---- |
| 2 |  | Vector calculus | \- Chain rule \- Vector calculus |
| 3 |  | Optimization | \- Gradient descent \- Constrained Optimization and Lagrange Multipliers |
| 4 |  | Probability | \- Probability \- Random variable \- Sum, product rules, Bayes theorem \- Mean, variance \- Gaussian distribution |
| 5 | Introduction | Introduction to Machine Learning | \- What is Machine Learning \- Types of Machine Learning problems \- Application of Machine Learning |
| 6 | Regression and Classification algorithms | Maximum Likelihood Estimation (MLE) | \- Maximum Likelihood Estimation \- Linear regression model \- Non-linear models in linear regression |
| 7 |  | Maximum A Posterior (MAP) | \- Evaluation metric to regression task \- Underfitting/overfitting \- Maximum A Posterior \- L1/L2 regularization \- Ridge/Lasso/Elasticnet Regression |
| 8 |  | Logistic Regression | \- Logistic Regression \- Decision Boundary \- Evaluation metric to the classification task |
| 9 |  | Naive Bayes | \- Naive Bayes algorithm \- Text classification problem |
| 10 |  | Support Vector Machine | \- SVM algorithm \- Kernel SVM \- Soft SVM |
| 11 |  | Decision Tree | \- Decision Tree algorithm \- How to implement Decision Tree \- Handle overfitting in Decision Tree \- Parameter tuning |
| 12 | Ensemble algorithms | Random Forest | \- Bagging vs boosting \- Decision Tree overfitting \- Random Forest algorithm |
| 13 |  | Adaboost | \- Adaboost algorithm |
| 14 |  | Gradient Boosting | \- Gradient Boosting algorithm |
| 15 |  | XGBoost & LightGBM | \- Introduce XGBoost & LightGBM \- Tips for best practice |
| **Final Project** |  |  |  |

